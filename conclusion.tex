\chapter{Conclusion and future work}
\section{Conclusion}
\subsection{HACD}
In this thesis as a baseline comparison a well established open source physics engine
(Bullet) has been used to simulate concave objects through Hierarchical approximate
 convex decomposition. This method has been investigated previously and there were
 indications that it would produce good results. It has therefore been implemented
 and tested for the purpose of acting as a baseline comparison.

As suspected the Bullet with HACD produces good result with decent performance and
the method includes very few design parameters. The approach with using HACD gives
a robust and easily managed solution, with the only drawback being that the HACD
may produce unexpected results for certain meshes. However, when this does happen
one always have the alternative to design the sub shapes by hand in external applications.

\subsection{Spherical decomposition}
In this thesis I have shown that a physics simulation based on impulses with
calculations performed on the GPU is possible. Certain performance optimizations
have been implemented but there are as always still more to have if more time is
spent on the problem. In terms of performance the proposed solution can match of the shelf
solutions (in the form of Bullet 2.83), when an object is decomposed into fewer than
218 particles.

The solution shows good promise, in addition to the results presented within this
thesis report is the release of Flex by~\cite{flex} at nVidia
during the course of the thesis, which uses some of the same core concepts.

Compared to HACD, voxelization is more intuitive and results are easier to modify
when needed. GPU code is in general more difficult to maintain than a CPU implementation.

\section{Future work}
In addition to pure optimization work which can almost always be done for almost any piece
of software the following are suggestions for future work and improvements.

The number of iterations needed for stability increase with increased stack sizes.
The reasons for this is motivated in section~\ref{sec:stabil}.
Two candidates to replace the stabilization iterations are
the approximate shock propagation method described by~\cite{flex} or the original
shock propagation method proposed by~\cite{guendelman}.

Making use of non-uniform structures such as oct-trees or kd-trees for the collision
detection, which would make the structure scale better with objects spread across
large distances.

Investigating the use of the Parallel-Sweep-And-Prune algorithm instead of the
uniform sorted grid for collision detection, a method which would most likely
benefit for larger objects as they work on bounding boxes and could be performed
in a two step fashion. First detecting whole bodies which may have collision.
Remove particles which belong to non-colliding bodies and redo the collision detection
on all remaining particles. In addition this method would support differently sized
particles better than the current one.

The collision carrier structure, the contact manifold, currently only carries
4 collisions per particle. This limits the system in two ways, the system can miss
collisions when more than 4 collisions occur simultaneously on a particle and the
system is unfit to use differently sized particles. The larger particles would
be likely to experience more simultaneous collisions than four and the system would
lose needed information. Extending this collision transfer structure to become dynamic
in size would be an interesting and needed feature, however it would most likely have
to be extended in a clever way as not to impact performance too heavily.

Solid halfspheres, as described by~\cite{flex}, is the idea that the spheres that
constitute the bodies can have modified normals on the inside of the objects to counteract
tunneling. When two bodies become tangled the solid halfspheres modified normals
on the inside of the object ensure that the objects push apart and separate.
